{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.jsonl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 42\u001b[0m\n\u001b[1;32m     34\u001b[0m transform_test \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m     35\u001b[0m     transforms\u001b[39m.\u001b[39mResize(size\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m),\n\u001b[1;32m     36\u001b[0m     transforms\u001b[39m.\u001b[39mCenterCrop(size\u001b[39m=\u001b[39m\u001b[39m224\u001b[39m),\n\u001b[1;32m     37\u001b[0m     transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m     38\u001b[0m     transforms\u001b[39m.\u001b[39mNormalize(mean\u001b[39m=\u001b[39m[\u001b[39m0.485\u001b[39m, \u001b[39m0.456\u001b[39m, \u001b[39m0.406\u001b[39m], std\u001b[39m=\u001b[39m[\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m])\n\u001b[1;32m     39\u001b[0m ])\n\u001b[1;32m     41\u001b[0m \u001b[39m# Load the datasets\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m train_dataset \u001b[39m=\u001b[39m HatefulMemeDataset(\n\u001b[1;32m     43\u001b[0m     json_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain.jsonl\u001b[39;49m\u001b[39m\"\u001b[39;49m, img_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mimg/\u001b[39;49m\u001b[39m\"\u001b[39;49m, transform\u001b[39m=\u001b[39;49mtransform_train)\n\u001b[1;32m     44\u001b[0m val_dataset \u001b[39m=\u001b[39m HatefulMemeDataset(\n\u001b[1;32m     45\u001b[0m     json_file\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdev.jsonl\u001b[39m\u001b[39m\"\u001b[39m, img_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg/\u001b[39m\u001b[39m\"\u001b[39m, transform\u001b[39m=\u001b[39mtransform_test)\n\u001b[1;32m     46\u001b[0m test_dataset \u001b[39m=\u001b[39m HatefulMemeDataset(\n\u001b[1;32m     47\u001b[0m     json_file\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest.jsonl\u001b[39m\u001b[39m\"\u001b[39m, img_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mimg/\u001b[39m\u001b[39m\"\u001b[39m, transform\u001b[39m=\u001b[39mtransform_test)\n",
      "Cell \u001b[0;32mIn[2], line 6\u001b[0m, in \u001b[0;36mHatefulMemeDataset.__init__\u001b[0;34m(self, json_file, img_dir, transform)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_dir \u001b[39m=\u001b[39m img_dir\n\u001b[1;32m      4\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39m=\u001b[39m transform\n\u001b[0;32m----> 6\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(json_file, \u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m      7\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m [json\u001b[39m.\u001b[39mloads(line) \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m f]\n",
      "File \u001b[0;32m~/a/dl_assignments/.venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.jsonl'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "class HatefulMemeDataset(Dataset):\n",
    "    def __init__(self, json_file, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(json_file, \"r\") as f:\n",
    "            self.data = [json.loads(line) for line in f]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.data[index][\"img\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.data[index][\"label\"]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Define the image transformations for data augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = HatefulMemeDataset(\n",
    "    json_file=\"train.jsonl\", img_dir=\"img/\", transform=transform_train)\n",
    "val_dataset = HatefulMemeDataset(\n",
    "    json_file=\"dev.jsonl\", img_dir=\"img/\", transform=transform_test)\n",
    "test_dataset = HatefulMemeDataset(\n",
    "    json_file=\"test.jsonl\", img_dir=\"img/\", transform=transform_test)\n",
    "\n",
    "# Define the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64,\n",
    "                          shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64,\n",
    "                        shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64,\n",
    "                         shuffle=False, num_workers=4)\n",
    "\n",
    "# Define the ResNet-50 model\n",
    "model = resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    # Train loop\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images).squeeze()\n",
    "\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        train_correct += ((outputs >= 0.5).int() == labels).sum().item()\n",
    "\n",
    "train_loss = train_loss / len(train_loader.dataset)\n",
    "train_acc = train_correct / len(train_loader.dataset)\n",
    "\n",
    "# Validation loop\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "val_correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images).squeeze()\n",
    "\n",
    "        loss = criterion(outputs, labels.float())\n",
    "\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "        val_correct += ((outputs >= 0.5).int() == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc = val_correct / len(val_loader.dataset)\n",
    "\n",
    "    # Print the epoch results\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} -- Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Check if this is the best model so far based on validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"resnet50_hateful_memes.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).squeeze()\n",
    "\n",
    "        loss = criterion(outputs, labels.float())\n",
    "\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        test_correct += ((outputs >= 0.5).int() == labels).sum().item()\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_acc = test_correct / len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
