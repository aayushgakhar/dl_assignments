{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet50\n",
    "from torchvision import models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HatefulMemeDataset(Dataset):\n",
    "    def __init__(self, json_file, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(json_file, \"r\") as f:\n",
    "            self.data = [json.loads(line) for line in f]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.img_dir, self.data[index][\"img\"])\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        label = self.data[index][\"label\"]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Define the image transformations for data augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(size=256),\n",
    "    transforms.CenterCrop(size=224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the datasets\n",
    "train_dataset = HatefulMemeDataset(\n",
    "    json_file=\"data/train.jsonl\", img_dir=\"data/\", transform=transform_train)\n",
    "val_dataset = HatefulMemeDataset(\n",
    "    json_file=\"data/dev.jsonl\", img_dir=\"data/\", transform=transform_test)\n",
    "test_dataset = HatefulMemeDataset(\n",
    "    json_file=\"data/test.jsonl\", img_dir=\"data/\", transform=transform_test)\n",
    "\n",
    "# Define the dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64,\n",
    "                          shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64,\n",
    "                        shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64,\n",
    "                         shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aayush/a/dl_assignments/.venv/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/aayush/a/dl_assignments/.venv/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /home/aayush/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 34.4MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 -- Train Loss: 0.2966, Val Loss: 1.4925, Train Acc: 0.8602, Val Acc: 0.5140\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define the ResNet-50 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 1)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Move the model and loss function to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion.to(device)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    # Train loop\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images).squeeze()\n",
    "\n",
    "        loss = criterion(outputs, labels.float())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        train_correct += ((outputs >= 0.5).int() == labels).sum().item()\n",
    "\n",
    "train_loss = train_loss / len(train_loader.dataset)\n",
    "train_acc = train_correct / len(train_loader.dataset)\n",
    "\n",
    "# Validation loop\n",
    "model.eval()\n",
    "val_loss = 0\n",
    "val_correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images).squeeze()\n",
    "\n",
    "        loss = criterion(outputs, labels.float())\n",
    "\n",
    "        val_loss += loss.item() * images.size(0)\n",
    "        val_correct += ((outputs >= 0.5).int() == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_acc = val_correct / len(val_loader.dataset)\n",
    "\n",
    "    # Print the epoch results\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} -- Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "    # Check if this is the best model so far based on validation loss\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"resnet50_hateful_memes.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).squeeze()\n",
    "\n",
    "        loss = criterion(outputs, labels.float())\n",
    "\n",
    "        test_loss += loss.item() * images.size(0)\n",
    "        test_correct += ((outputs >= 0.5).int() == labels).sum().item()\n",
    "    \n",
    "    test_loss = test_loss / len(test_loader.dataset)\n",
    "    test_acc = test_correct / len(test_loader.dataset)\n",
    "\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
